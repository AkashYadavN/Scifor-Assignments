{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODDmn8PvAXYGNnjhFHEwbq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkashYadavN/Scifor-Assignments/blob/main/ML_Implementation_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KARMyVR11bTe",
        "outputId": "a7e82134-167b-43fd-b816-bdda2ed04a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Implementation of Decision Tree Classifier by applying Hyperparameter Tuning\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the decision tree classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the classifier with the best hyperparameters\n",
        "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
        "best_dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = best_dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementation of Naive Bayes Classifier by applying Hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Define the model\n",
        "model = GaussianNB()\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "params = {}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Get best hyperparameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDc9dWMX71Gp",
        "outputId": "135cc4e8-7ce3-49b4-b030-3083f5fc5c63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {}\n",
            "Best Score: 0.9533333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementation of Support Vector Machine by applying Hyperparameter tuning\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the SVM classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Define the hyperparameters grid for tuning\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Perform grid search cross-validation\n",
        "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "# Evaluate the classifier on the test set\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ5_BaID76l2",
        "outputId": "fe10cd8c-e805-401c-91ef-05dd720857bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "Best Score: 0.9714285714285715\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain Various types of Kernel with respect to the formula.\n",
        "\n",
        "**Linear Kernel** :- A linear kernel is a type of kernel function used in machine learning, particularly in support vector machines (SVMs) and kernelized versions of algorithms such as kernelized ridge regression.\n",
        "Mathematically, for two vectors **x** and **y**.\n",
        "\n",
        "K(x,y)=x^\n",
        "T\n",
        " ⋅y\n",
        "where\n",
        "\n",
        "x^\n",
        "T\n",
        "  denotes the transpose of\n",
        "x.\n",
        "\n",
        "**Polynomial Kernel**:- A polynomial kernel is another type of kernel function commonly used in machine learning, especially in support vector machines (SVMs) and kernelized versions of algorithms. Unlike the linear kernel, which computes the dot product between input vectors, the polynomial kernel computes a similarity measure that is based on polynomial functions of the original features.\n",
        "K(x,y)=(x^\n",
        "T\n",
        " ⋅y+c)^\n",
        "d\n",
        "where:\n",
        "\n",
        "x and\n",
        "y are input data points,\n",
        "c is a constant (often denoted as the bias term),\n",
        "d is the degree of the polynomial.\n",
        "\n",
        "**Gaussian Kernel**:-\n",
        "The Gaussian kernel, also known as the radial basis function (RBF) kernel, is a popular kernel function used in machine learning, particularly in support vector machines (SVMs) and kernelized versions of algorithms.\n",
        "\n",
        "**Sigmoid Kernel** :- The sigmoid kernel is another type of kernel function used in machine learning, particularly in support vector machines (SVMs) and kernelized versions of algorithms.\n",
        "K(x,y)=tanh(α⋅x\n",
        "T\n",
        " ⋅y+β)\n",
        "\n",
        " where:\n",
        "\n",
        "\n",
        "x and\n",
        "y are input data points,\n",
        "\n",
        "α and\n",
        "β are hyperparameters that control the shape and scaling of the kernel."
      ],
      "metadata": {
        "id": "jSotMagx8A2S"
      }
    }
  ]
}